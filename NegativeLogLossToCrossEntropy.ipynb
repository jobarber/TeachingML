{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to get cross entropy from negative log loss\n",
        "\n",
        "Cross entropy takes the negative log loss of the log softmax of y_pred."
      ],
      "metadata": {
        "id": "ktHNH_v1IA_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up"
      ],
      "metadata": {
        "id": "DP1zVY44Iil7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-cnBMAhMtpB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = torch.tensor([1, 0, 0, 1, 0, 1, 0, 2])\n",
        "y_pred = torch.tensor([[1., 0, 0],\n",
        "                       [0, 1, 0],\n",
        "                       [1, 0, 0],\n",
        "                       [0, 1, 0],\n",
        "                       [0, 1, 0],\n",
        "                       [0, 1, 0],\n",
        "                       [0, 1, 0],\n",
        "                       [0, 0, 1]])"
      ],
      "metadata": {
        "id": "NNMbvko7MyJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch"
      ],
      "metadata": {
        "id": "YZdo1_DCIkuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(y_pred, y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlwqJdIsNTWg",
        "outputId": "9acbd753-ed0f-475b-fee2-8ebee299063c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0514)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.nll_loss(torch.log_softmax(y_pred, dim=-1), y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNzX26OkM-6I",
        "outputId": "78bd6e8a-41dd-48bb-9f43-dff1fd1f354e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0514)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.log_softmax(y_pred, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax_2EgpjFoQ3",
        "outputId": "11cd7010-40d9-4f6a-8f89-2ffad6d0248b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5514, -1.5514, -1.5514],\n",
              "        [-1.5514, -0.5514, -1.5514],\n",
              "        [-0.5514, -1.5514, -1.5514],\n",
              "        [-1.5514, -0.5514, -1.5514],\n",
              "        [-1.5514, -0.5514, -1.5514],\n",
              "        [-1.5514, -0.5514, -1.5514],\n",
              "        [-1.5514, -0.5514, -1.5514],\n",
              "        [-1.5514, -1.5514, -0.5514]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sklearn\n",
        "Cross entropy takes the negative log loss of the log softmax of y_pred."
      ],
      "metadata": {
        "id": "gQl5JJU_IZ9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import log_softmax, softmax\n",
        "from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "id": "2jS8LHsCJKfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_true.numpy()\n",
        "y_pred = y_pred.numpy()"
      ],
      "metadata": {
        "id": "FjS9tQ6lH9BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss(y_true, softmax(y_pred))  # the log is already included in the loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJY9NRYPI6QU",
        "outputId": "de8d4bf7-1830-4afe-e5e3-615ce9cfb781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0514447093009949"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss(y_true, np.exp(y_pred) / np.sum(np.exp(y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TybXHXDFJqWm",
        "outputId": "ba91d8cf-ddbd-4407-cbc1-7fef2e77c781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0514447093009949"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}