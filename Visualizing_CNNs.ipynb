{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-MCg4acEUDv"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTd6zqvp-cRC"
      },
      "source": [
        "import re\n",
        "import requests\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb17yFnLltIX"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbvbGLHg-3tX"
      },
      "source": [
        "resnet = resnet50(pretrained=True).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSkkTp2V--et"
      },
      "source": [
        "resnet.eval()\n",
        "resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnGPhacb_AEI"
      },
      "source": [
        "image_response = requests.get('https://upload.wikimedia.org/wikipedia/commons/5/56/White_shark.jpg',\n",
        "                              stream=True)\n",
        "label_response = requests.get('https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKjAZmOSABV0"
      },
      "source": [
        "image = transforms.functional_pil.Image.open(image_response.raw)\n",
        "image = transforms.functional.resize(image, (image.size[1] // 2, image.size[0] // 2))\n",
        "image_tensor = transforms.functional.to_tensor(image).to(device)\n",
        "image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY62KthKEXLM"
      },
      "source": [
        "## Visualize Select Layer Activations (Outputs) of a Given Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YCGmMoHxv6v"
      },
      "source": [
        "#### Plot the output of every channel for the first layer/activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUWGCYShEnMb"
      },
      "source": [
        "with torch.no_grad():\n",
        "    conv1_output = resnet.conv1(image_tensor.unsqueeze(0))\n",
        "    bn1_output = resnet.bn1(conv1_output)\n",
        "    first_activation_output = resnet.relu(bn1_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRxNiL_CNRgH"
      },
      "source": [
        "first_activation_output.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEckcEsJFtK_"
      },
      "source": [
        "transforms.functional.to_pil_image(make_grid(first_activation_output.permute(1, 0, 2, 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8n2CzroxFTt"
      },
      "source": [
        "#### Plot the output for every channel in the last CNN layer/activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gde6RpkQx0vT"
      },
      "source": [
        "with torch.no_grad():\n",
        "    x = image_tensor.unsqueeze(0)\n",
        "    for name, child in resnet.named_children():\n",
        "        x = child(x)\n",
        "        if name == 'layer4':\n",
        "            break\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh3D7d4IymGc"
      },
      "source": [
        "transforms.functional.to_pil_image(make_grid(x.permute(1, 0, 2, 3), nrow=56))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGfr-O4d8Ur8"
      },
      "source": [
        "## Visualize the weights (of each filter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKuYAHy48YFE"
      },
      "source": [
        "resnet.conv1.weight.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDXICGLCDHP5"
      },
      "source": [
        "transforms.functional.to_pil_image(make_grid(resnet.conv1.weight))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpp8ZfwZDQBG"
      },
      "source": [
        "#### Now zoom in on the above filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjiGqQ7qDX3Y"
      },
      "source": [
        "transforms.functional.to_pil_image(transforms.functional.resize(make_grid(resnet.conv1.weight), 56 * 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQhNqQvVDqal"
      },
      "source": [
        "#### Now visualize **a small portion of** (3 / 512) the last weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYZW20ChDtwl"
      },
      "source": [
        "resnet.layer4[1].conv2.weight.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSFIcRdzEEZ_"
      },
      "source": [
        "transforms.functional.to_pil_image(make_grid(resnet.layer4[1].conv2.weight[:, :3, :, :], nrow=32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dygdIzSMFE4t"
      },
      "source": [
        "#### Now zoom in on the above image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2RTUM7FFIc4"
      },
      "source": [
        "transforms.functional.to_pil_image(transforms.functional.resize(make_grid(resnet.layer4[1].conv2.weight[:, :3, :, :], nrow=32), 128 * 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BzxK6S9FjxD"
      },
      "source": [
        "## Occlude part of the image sequentially to identify hotspots that are the reason for the most probable classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ToAgtrQGyS5"
      },
      "source": [
        "image_tensor.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vsSpoTbFus2"
      },
      "source": [
        "block_size = 20\n",
        "heatmap = torch.clone(image_tensor)\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    initial_prediction = torch.softmax(resnet(image_tensor.unsqueeze(0)), dim=-1)\n",
        "    prediction_index = torch.argmax(initial_prediction, dim=-1).item()\n",
        "    prediction_probability = initial_prediction[0][prediction_index]\n",
        "for i in range(0, image_tensor.shape[1] - block_size, 10):\n",
        "    for j in range(0, image_tensor.shape[2] - block_size, 10):\n",
        "        with torch.no_grad():\n",
        "            blocked_image = torch.clone(image_tensor).to(device)\n",
        "            blocked_image[:, i:i + block_size, j:j + block_size] = torch.zeros(3, block_size, block_size)\n",
        "            prediction = torch.softmax(resnet(blocked_image.unsqueeze(0)), dim=-1)\n",
        "            red = 1. if prediction[0][prediction_index] > prediction_probability + 0.03 else 0.\n",
        "            blue = 1. if prediction[0][prediction_index] < prediction_probability - 0.03 else 0.\n",
        "            heatmap[0, i:i + block_size, j:j + block_size] += red\n",
        "            heatmap[2, i:i + block_size, j:j + block_size] += blue\n",
        "heatmap = torch.clamp(heatmap, min=0, max=1)\n",
        "heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHLXBtyzIpSj"
      },
      "source": [
        "transforms.functional.to_pil_image(make_grid(heatmap))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e422BtZEPja"
      },
      "source": [
        "## Making a classification prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQz62ifJAFQP"
      },
      "source": [
        "with torch.no_grad():\n",
        "    prediction = resnet(image_tensor.unsqueeze(0))  # have to unsqueeze to make a batch (of 1) out of image\n",
        "    print('size of response for classification:', prediction.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WTfA0Y1BSjo"
      },
      "source": [
        "labels = eval(label_response.text)\n",
        "len(labels), list(labels.items())[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZE0AtOTDu9W"
      },
      "source": [
        "topk = torch.topk(torch.softmax(prediction, dim=-1), 5, dim=-1)\n",
        "topk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yemQEXJjEBQw"
      },
      "source": [
        "print(f'Made the following prediction with a softmax probability of {topk.values[0][0]}:')\n",
        "labels[topk.indices[0][0].item()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gfcke4iQShA"
      },
      "source": [
        "## TO DO: Retrieving images that maximally activate a neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Bo5NAlPuhO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKqNidC3QgHH"
      },
      "source": [
        "## TO DO: Embedding the codes with t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Y0Ub_WQkGJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}