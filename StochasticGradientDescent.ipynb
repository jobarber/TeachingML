{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZoVKyJC0lCk"
      },
      "source": [
        "# Reproduce the paper example with a linear layer followed by a sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv5ViBBdfUR5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7QojxBv1FoQ"
      },
      "source": [
        "## Set up the linear layer with the weights and bias in the paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5F68Bqbfcbf"
      },
      "source": [
        "linear = nn.Linear(2, 1)\n",
        "linear.weight = nn.Parameter(torch.tensor([[2., -3.]]))\n",
        "linear.bias = nn.Parameter(torch.tensor([-3.]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q51YQVHCsBkf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d856ddf8-face-4581-86b8-3b0a635fb0d9"
      },
      "source": [
        "# sanity check; do these weights look like the paper?\n",
        "print(linear, linear.weight.data, linear.bias.data, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=2, out_features=1, bias=True)\n",
            "tensor([[ 2., -3.]])\n",
            "tensor([-3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkeC6NAI1wlh"
      },
      "source": [
        "## Your code goes here: finding gradients\n",
        "1. Create a tensor called `inputs` here (refer to [this documentation](https://pytorch.org/docs/master/generated/torch.tensor.html) for a reminder on how to create a tensor).\n",
        "2. Use the linear layer followed by a sigmoid layer to predict the `output`. See the [documentation on predicting with a model here](https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward) (to call a layer or module simply add `()` after the name of the module or layer with one argument). Also see the [documentation on `sigmoid` here](https://pytorch.org/docs/stable/nn.functional.html#sigmoid) (note the equation). You can reference `sigmoid` with `F.sigmoid`.\n",
        "3. Call the `backward` method on the `output`.\n",
        "4. Check `linear.weight.grad` and `linear.bias.grad`. Do they reflect your calculations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA7g9okqlWiS"
      },
      "source": [
        "# x = -1., -2.\n",
        "inputs = torch.tensor([[-1., -2.]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF888ar_mHSY"
      },
      "source": [
        "output = torch.sigmoid(linear(inputs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpdlqpCZm5jl"
      },
      "source": [
        "# call backward\n",
        "output.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiUqUs6VsWIV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bce3a613-fc94-4588-f624-b41133073d57"
      },
      "source": [
        "# check the gradients\n",
        "linear.weight.grad, linear.bias.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.1966, -0.3932]]), tensor([0.1966]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RhPt1Or-Ypq"
      },
      "source": [
        "## Applying over batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VriN4APb__2w"
      },
      "source": [
        "### Zero out the grads before adding the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qYUspb5jiab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02b8c9d7-b3e1-4e3e-ea08-112aa4454c6f"
      },
      "source": [
        "# zero the gradients from above\n",
        "linear.weight.grad.zero_()\n",
        "linear.bias.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISNJFV5E-ghj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "5ca48566-8caa-41a3-a5e2-802079ffb9d5"
      },
      "source": [
        "for epoch in range(10):\n",
        "\n",
        "    output = torch.sigmoid(linear(inputs))\n",
        "    loss = output - 1.\n",
        "    loss.backward()\n",
        "\n",
        "    grad = linear.weight.grad\n",
        "    learning_rate = 0.1\n",
        "    linear.weight = torch.nn.Parameter(linear.weight - loss * linear.weight.grad)\n",
        "    linear.bias = torch.nn.Parameter(linear.bias - loss * linear.bias.grad)\n",
        "\n",
        "    print('loss:', loss, 'weights:', linear.weight.data, 'grad:', grad, 'model output:', torch.sigmoid(linear(inputs)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: tensor([[-0.2689]], grad_fn=<SubBackward0>) weights: tensor([[ 1.9471, -3.1058]]) grad: tensor([[-0.1966, -0.3932]]) model output: tensor([[0.7887]], grad_fn=<SigmoidBackward>)\n",
            "loss: tensor([[-0.2113]], grad_fn=<SubBackward0>) weights: tensor([[ 1.9119, -3.1762]]) grad: tensor([[-0.1666, -0.3333]]) model output: tensor([[0.8218]], grad_fn=<SigmoidBackward>)\n",
            "loss: tensor([[-0.1782]], grad_fn=<SubBackward0>) weights: tensor([[ 1.8858, -3.2284]]) grad: tensor([[-0.1465, -0.2929]]) model output: tensor([[0.8436]], grad_fn=<SigmoidBackward>)\n",
            "loss: tensor([[-0.1564]], grad_fn=<SubBackward0>) weights: tensor([[ 1.8652, -3.2696]]) grad: tensor([[-0.1320, -0.2639]]) model output: tensor([[0.8592]], grad_fn=<SigmoidBackward>)\n",
            "loss: tensor([[-0.1408]], grad_fn=<SubBackward0>) weights: tensor([[ 1.8482, -3.3037]]) grad: tensor([[-0.1210, -0.2419]]) model output: tensor([[0.8711]], grad_fn=<SigmoidBackward>)\n",
            "loss: tensor([[-0.1289]], grad_fn=<SubBackward0>) weights: tensor([[ 1.8337, -3.3326]]) grad: tensor([[-0.1123, -0.2245]]) model output: tensor([[0.8806]], grad_fn=<SigmoidBackward>)\n",
            "loss: tensor([[-0.1194]], grad_fn=<SubBackward0>) weights: tensor([[ 1.8211, -3.3577]]) grad: tensor([[-0.1052, -0.2103]]) model output: tensor([[0.8883]], grad_fn=<SigmoidBackward>)\n",
            "loss: tensor([[-0.1117]], grad_fn=<SubBackward0>) weights: tensor([[ 1.8100, -3.3799]]) grad: tensor([[-0.0992, -0.1985]]) model output: tensor([[0.8947]], grad_fn=<SigmoidBackward>)\n",
            "loss: tensor([[-0.1053]], grad_fn=<SubBackward0>) weights: tensor([[ 1.8001, -3.3998]]) grad: tensor([[-0.0942, -0.1884]]) model output: tensor([[0.9002]], grad_fn=<SigmoidBackward>)\n",
            "loss: tensor([[-0.0998]], grad_fn=<SubBackward0>) weights: tensor([[ 1.7912, -3.4177]]) grad: tensor([[-0.0899, -0.1797]]) model output: tensor([[0.9049]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVsNBfKFcDQn"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}